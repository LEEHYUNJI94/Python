{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\a201909072\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\a201909072\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from bs4) (4.8.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\a201909072\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bs4 기본사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버를 시작페이지로\n"
     ]
    }
   ],
   "source": [
    "import requests,urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#####1.urllib로 HTML DATA 갖고오기#####\n",
    "naver_url = 'https://www.naver.com/'\n",
    "html=urllib.request.urlopen(naver_url).read()\n",
    "# print(html)\n",
    "\n",
    "#####2.requests로 HTML DATA가져오기#####\n",
    "response=requests.get(naver_url)\n",
    "# print(response.content)\n",
    "\n",
    "#####1. Bs4로 HTML DATA가져오기#####\n",
    "bsObj=bs4.BeautifulSoup(html,'html.parser')\n",
    "# print(bsObj)\n",
    "#####2. Bs4로 HTML DATA가져오기#####\n",
    "bs_obj=BeautifulSoup(response.content,'html.parser')\n",
    "# print(bs_obj)\n",
    "\n",
    "\n",
    "#####원하는 부분 가져오기#####\n",
    "top_right=bsObj.find('div',{'class':'area_links'})\n",
    "# print(top_right)\n",
    "# a 태그가 있는 부분의 text만 추출\n",
    "print(top_right.find('a').text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bs4 실습1-뉴스기사 헤드라인 뽑기\n",
    "-findAll 사용해서 list로 만든 후 인덱스로 접근해 data 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긴급재난지원금 지급 기준 아직 모른다…중산층 '혼선'\n",
      "한 건물서 224명 확진…대남병원보다 큰 규모, 주변 상인 '울분'\n",
      "대구서 코로나19 확진 60대 남성 숨져…국내 사망자 162명\n",
      "교사 75% '4월 6일' 개학 반대…\"수능도 늦춰야\"\n",
      "조주빈 '영상녹화실'서 3차 검찰 조사…31일도 소환 방침\n",
      "총선 D-16…민주·통합, 비례정당 선대위 띄우며 쌍끌이 총력전\n",
      "윤곽나온 3기 신도시…걸어서 10분내 지하철·상가 공실 최소화\n",
      "'타다' 유사서비스 '파파'도 재판 갈까…기소의견 송치\n",
      "'검찰 성폭력 은폐 의혹' 사건 불기소…임은정 \"재정신청할 것\"\n",
      "181억 받은 신동빈, 총수 연봉 1위…엔씨소프트 배재현 162억원\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "url=\"https://www.naver.com/\"\n",
    "naver_html=urllib.request.urlopen(url).read()\n",
    "bsObj=bs4.BeautifulSoup(naver_html,'html.parser')\n",
    "ca_l=bsObj.find('ol',{'class':'ca_l'}) #추출할 부분 찾기\n",
    "list_lis=ca_l.findAll(\"li\") #list형으로 만듦-태그 사이 공백제거[<li></li>,<li></li>]\n",
    "\n",
    "for li in list_lis :     #[0,1,2.3...]인덱스로 데이터를 뽑을 수 있음\n",
    "    print(li.find(\"a\").text) #{'class':'ca_a'} 해도 안해도 결과값 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bs4 실습2-주가가져오기1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47,850 won\n"
     ]
    }
   ],
   "source": [
    "import urllib.request,bs4\n",
    "\n",
    "#bsObjebt만드는 함수 생성-삼성전자 \n",
    "def get_bs_Obj():\n",
    "    fin_html=urllib.request.urlopen(\"https://finance.naver.com/item/main.nhn?code=005930\").read()  #005930:삼성전자 comco\n",
    "    bsObj=bs4.BeautifulSoup(fin_html,\"html.parser\")\n",
    "    return bsObj\n",
    "\n",
    "#삼성전자 주가가져오는 함수\n",
    "def get_price(bsObj):\n",
    "    no_today=bsObj.find(\"p\",{\"class\":\"no_today\"})\n",
    "    blind=no_today.find(\"span\",{\"class\":\"blind\"})\n",
    "    return blind.text      #print(blind.text)을 함수로 사용하기 위해 return으로 사용\n",
    "\n",
    "\n",
    "bsObj=get_bs_Obj()\n",
    "price=get_price(bsObj)\n",
    "print(price,\"won\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bs4 실습2-주가가져오기2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005930 47,850\n",
      "000660 83,700\n",
      "005680 6,810\n"
     ]
    }
   ],
   "source": [
    "import urllib.request,bs4\n",
    "\n",
    "\n",
    "def get_bsObj(companycode):   #companycode parameter을 넘겨줘야함\n",
    "    Finance_html=urllib.request.urlopen(\"https://finance.naver.com/item/main.nhn?code=\" + companycode).read()\n",
    "    Finance_bsObj=bs4.BeautifulSoup(Finance_html,'html.parser')\n",
    "    return Finance_bsObj\n",
    "\n",
    "def get_com_price(companycode):\n",
    "    bs_Obj=get_bsObj(companycode)\n",
    "    no_today=bs_Obj.find(\"p\",{\"class\":\"no_today\"})\n",
    "    blind=no_today.find(\"span\",{\"class\":\"blind\"})\n",
    "    return blind.text\n",
    "\n",
    "company_code_list=[\"005930\",\"000660\",\"005680\"]\n",
    "for item in company_code_list:\n",
    "    print(item,get_com_price(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
